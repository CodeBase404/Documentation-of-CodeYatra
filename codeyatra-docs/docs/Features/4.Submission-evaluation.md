---
title: Submission Evaluation
description: Understand how code submissions are evaluated, judged, and scored.
sidebar_label: Submission Evaluation
---

# ğŸ§  Submission Evaluation

Once a user submits their solution, the platform runs it against a defined set of **hidden test cases** and returns a detailed **verdict**. This evaluation process ensures that only correct and efficient solutions are accepted.

---

## âš™ï¸ Evaluation Workflow

### 1. ğŸ“¤ Code Submission

When the user clicks **Submit**, we collect:
- Selected language (e.g., C++, Java, JS)
- Problem ID
- Submitted code

```ts
POST /api/submit
{
  problemId: "xyz123",
  language: "cpp",
  code: "..."
}
```

### 2. ğŸ§ª Run Against Hidden Test Cases
The backend fetches hidden test cases from the database.

Each test case is passed to the code execution engine (like Judge0).

The user's code is run in a sandboxed environment for safety.

```js
hiddenTestCases.forEach(tc => {
  sendToJudge0({
    code,
    language,
    input: tc.input,
    expectedOutput: tc.output
  });
});
```

### 3. âš–ï¸ Verdict Calculation
For each test case, we store:

âœ… Pass/Fail status

ğŸ•’ Execution time

ğŸ§  Memory usage

ğŸ§¾ Standard output/error

If all hidden test cases pass, verdict = Accepted
Else, verdict = Wrong Answer, TLE, Runtime Error, or Compilation Error

###ğŸ§¾ Sample Response

```json
{
  status: "Accepted",
  passedCount: 10,
  totalCount: 10,
  runtime: "120ms",
  memory: "14MB",
  testCaseResults: [
    { input: "1 2", expected: "3", output: "3", status: "Pass" },
    ...
  ]
}
```

### ğŸ“ˆ Verdict Types

| Verdict                      | Description                                                |
| ---------------------------- | ---------------------------------------------------------- |
| âœ… Accepted                   | Code passed all hidden test cases                          |
| âŒ Wrong Answer               | Output didn't match expected result                        |
| ğŸ•’ Time Limit Exceeded (TLE) | Took longer than max allowed time per test case            |
| ğŸ’¥ Runtime Error             | Crashed during execution (e.g., divide by 0, null pointer) |
| ğŸš« Compilation Error         | Code failed to compile                                     |

### ğŸ“¦ Data Stored in DB

In the ``Submission`` model:

```json
{
  userId: "user123",
  problemId: "xyz123",
  code: "...",
  language: "cpp",
  status: "Accepted",
  runtime: "120ms",
  memory: "14MB",
  timeStamp: Date.now()
}
```

### ğŸ† Updating User Profile
If verdict = Accepted:

Mark problem as solved in userâ€™s profile.

Update streak, points, or XP.

```js
User.findByIdAndUpdate(userId, {
  $addToSet: { problemSolved: problemId }
});
```

### ğŸ¯ Accuracy & Fairness
Test cases include edge conditions and randomized inputs

Evaluation uses standard I/O for fairness

All code runs in secure (judge0)

### ğŸ–¥ï¸ UI Display
Verdict badge (e.g., green for Accepted)

Runtime and memory display

Detailed per-test-case feedback (optional)

```jsx
<SubmissionResult
  status="Accepted"
  runtime="120ms"
  memory="14MB"
  testCaseResults={[...]}
 />
```

ğŸ“˜ Next: [Contest Mode â†’](./5.Contest-mode.md)